# Spark study 1주차

- 데이터 브릭스 로그인 이슈로 마크다운에 기록

## sarpk 기본 아키텍처

- 클러스터? 다수의 컴퓨터 자원을 모아서 하나처럼 사용하는 것
<br/>
하나처럼 사용하려면 이 다수의 컴퓨팅 시스템을 조율하는 컴포넌트가 필요한데, spark는 이를 지원한다.(데이터 처리 작업을 조율, 관리) <br/>
spark 실행을 지원하는 클러스터는
- Hadoop YARN
- 스탠드얼론 클러스터 매니저
- 메소스
<br/>

### 스파크 애플리케이션

- 하나의 driver와 다수의 executor로 구성
<br/>
- driver는 클러스터 노드 중 하나에서 실행되며, main() 함수를 실행, 사용자 프로그램과의 상호작용, executor 관리
    - executor 작업에 대한 분석, 배포, 스케줄링
- exector는 실제 작업을 실행, 작업에 대한 진행 상황을 driver에게 보고
<br/>
컴퓨팅 자원을 스파크 앱에 할당하는 주체? -> 클러스터 매니저

### 파티션
- executor에서 실행되는 최소 작업 단위
- row의 집합

<br/>

### 트랜스포메이션
- spark 데이터는 immutable
- 트랜스포메이션은 데이터에 변경하는 방법이며, 실제 수행은 하지않음
- 비즈니스 로직을 표현
- 좁은 의존성과 넓은 의존성을 갖는다.

**좁은 의존성**
하나의 출력 결과가 하나의 입력에만 영향 받음
<br/>
여러 필터를 지정하는 경우, 모든 작업이 메모리에서 수행
**넓은 의존성**
하나의 출력 결과가 다수의 입력 결과에 영향 받으며, 셔플이 발생
- 셔플의 결과는 디스크에 저장됨
<br/>

### 지연 연산
- spark는 연산을 바로 수행하지 않음. 연산 그래프를 처리하기 직전까지 기다림

### 액션
- 실제 연산을 수행
- 

